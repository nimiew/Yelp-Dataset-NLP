{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of a Noun - Adjective Pair Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import ast\n",
    "import tqdm as tqdm\n",
    "import heapq\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_sentence(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    for k, token in enumerate(doc):\n",
    "        print(f\"TOKEN {k}: {token.text, token.pos_, token.tag_, token.dep_}\")\n",
    "        print(f\"HEAD: {token.head.text, token.head.pos_, token.head.tag_, token.head.dep_}\")\n",
    "        print(\"CHILDREN:\")\n",
    "        for child in token.children:\n",
    "            print(child.text, child.pos_, child.tag_, child.dep_)\n",
    "        print(\"ANCESTORS:\")\n",
    "        for ancestor in token.ancestors:\n",
    "            print(ancestor.text, ancestor.pos_, ancestor.tag_, ancestor.dep_)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note token has attribute 'i' that denotes its index in the document\n",
    "def get_noun_adjective_pairs_3(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    noun_adj_pairs = [] # [((noun_index, noun_text), (adj_index, adj_text)), ...]\n",
    "    \n",
    "    for token in doc:\n",
    "        '''\n",
    "        Intuition: Look for noun tokens and adjectives in local subtrees\n",
    "        '''\n",
    "        children = list(token.children)\n",
    "        if (token.tag_ in ['NN', 'NNS', 'NNP', 'NNPS']):\n",
    "            for child in children:\n",
    "                if (child.tag_ in ['JJ', 'JJR', 'JJS']):\n",
    "                    noun = [token.i, token.text.lower()]\n",
    "                    adj = [child.i, child.text.lower()]\n",
    "                    noun_adj_pairs.append([noun, adj])        \n",
    "        for i in range(len(children)-1):\n",
    "            for j in range(i+1, len(children)):\n",
    "                if children[i].tag_ in ['NN', 'NNS', 'NNP', 'NNPS'] and\\\n",
    "                children[j].tag_ in ['JJ', 'JJR', 'JJS']:\n",
    "                    noun = [children[i].i, children[i].text.lower()]\n",
    "                    adj = [children[j].i, children[j].text.lower()]\n",
    "                    noun_adj_pairs.append([noun, adj])\n",
    "                if children[i].tag_ in ['JJ', 'JJR', 'JJS'] and\\\n",
    "                children[j].tag_ in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "                    noun = [children[j].i, children[j].text.lower()]\n",
    "                    adj = [children[i].i, children[i].text.lower()]\n",
    "                    noun_adj_pairs.append([noun, adj])\n",
    "    \n",
    "    '''\n",
    "    Accounting for 'and'\n",
    "    '''\n",
    "    list_of_adj = [noun_adj_pair[1][0] for noun_adj_pair in noun_adj_pairs] # in terms of index\n",
    "    list_of_noun = [noun_adj_pair[0][0] for noun_adj_pair in noun_adj_pairs] # in terms of index\n",
    "    flag = True\n",
    "    while flag:\n",
    "        flag = False\n",
    "        for token in doc:\n",
    "            if token.tag_ in ['JJ', 'JJR', 'JJS']\\\n",
    "            and token.i not in list_of_adj\\\n",
    "            and token.head.i in list_of_adj:\n",
    "                head_adj_position = list_of_adj.index(token.head.i)\n",
    "                noun_position = list_of_noun[head_adj_position]\n",
    "                list_of_adj.append(token.i)\n",
    "                list_of_noun.append(noun_position)\n",
    "                noun_adj_pairs.append([[noun_position, doc[noun_position].text.lower()],\\\n",
    "                                       [token.i, token.text.lower()]])\n",
    "                flag = True\n",
    "\n",
    "    '''\n",
    "    Accounting for 'not'\n",
    "    '''\n",
    "    # Case one: head of 'not' is ADJ\n",
    "    for token in doc:\n",
    "        if token.text.lower() == 'not' and token.head.tag_ in ['JJ', 'JJR', 'JJS']:\n",
    "            to_negate = token.head.i\n",
    "            for noun_adj_pair in noun_adj_pairs:\n",
    "                if noun_adj_pair[1][0] == to_negate:\n",
    "                    if noun_adj_pair[1][1].startswith('not '):\n",
    "                        noun_adj_pair[1][1] = noun_adj_pair[1][1][4:]\n",
    "                    else:\n",
    "                        noun_adj_pair[1][1] = 'not ' + noun_adj_pair[1][1] \n",
    "    # Case two: head of 'not' is not ADJ -> Go to head,\n",
    "    # find the noun-adj pair under that head, and modify that.\n",
    "    for token in doc:\n",
    "        if token.text.lower() == 'not' and token.head.tag_ not in ['JJ', 'JJR', 'JJS']:\n",
    "            head_children = list(token.head.children)\n",
    "            # We just modify first noun-adj pair found under head\n",
    "            to_negate = None\n",
    "            for i in range(len(head_children)-1):\n",
    "                for j in range(i+1, len(head_children)):\n",
    "                    if head_children[i].tag_ in ['JJ', 'JJR', 'JJS'] and\\\n",
    "                    head_children[j].tag_ in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "                        to_negate = [head_children[j].i, head_children[i].i]\n",
    "                        break\n",
    "                    elif head_children[i].tag_ in ['NN', 'NNS', 'NNP', 'NNPS'] and\\\n",
    "                    head_children[j].tag_ in ['JJ', 'JJR', 'JJS']:\n",
    "                        to_negate = [head_children[i].i, head_children[j].i]\n",
    "                        break\n",
    "            if to_negate == None:\n",
    "                continue\n",
    "            for noun_adj_pair in noun_adj_pairs:\n",
    "                if noun_adj_pair[0][0] == to_negate[0] and noun_adj_pair[1][0] == to_negate[1]:\n",
    "                    if noun_adj_pair[1][1].startswith('not '):\n",
    "                        noun_adj_pair[1][1] = noun_adj_pair[1][1][4:]\n",
    "                    else:\n",
    "                        noun_adj_pair[1][1] = 'not ' + noun_adj_pair[1][1]\n",
    "         \n",
    "    filtered_noun_adj_pairs = [(noun_adj_pair[0][1], noun_adj_pair[1][1]) for noun_adj_pair in noun_adj_pairs]\n",
    "        \n",
    "    return filtered_noun_adj_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_adjective_pairs_2(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    noun_adj_pairs = []\n",
    "    \n",
    "    for token in doc:\n",
    "        child_pos = [child.pos_ for child in token.children]\n",
    "        '''\n",
    "        Intuition: Look for noun tokens and adjectives in local subtrees\n",
    "        '''\n",
    "        if (token.pos_ == 'NOUN'):\n",
    "            for child in token.children:\n",
    "                if (child.pos_ == 'ADJ'):\n",
    "                    noun_adj_pairs.append((token.text.lower(), child.text.lower()))        \n",
    "        elif (('NOUN' in child_pos) and ('ADJ' in child_pos)):\n",
    "            children = [child for child in token.children]\n",
    "            noun_adj_pairs.append((children[child_pos.index('NOUN')].text.lower(), children[child_pos.index('ADJ')].text.lower()))\n",
    "    \n",
    "    return noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_adjective_pairs(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    noun_adj_pairs = []\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.tag_ in ['NN']:\n",
    "            j = 1\n",
    "            direction = 1\n",
    "            while True:\n",
    "                if i+j*direction < 0  or i+j*direction >= len(doc):\n",
    "                    break\n",
    "                if doc[i+j*direction].tag_ in ['JJ']:\n",
    "                    noun_adj_pairs.append((token.text.lower(),\\\n",
    "                              doc[i+j*direction].text.lower()))\n",
    "                    break\n",
    "                direction *= -1\n",
    "                if direction == 1:\n",
    "                    j += 1    \n",
    "    return noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# business_ids = ['R4R7ttLXfKKWM0VEMoaW4w', '0kPm1zEpeXFRg8D2phqgCQ', '6RbCJLiwNYwS6ab9vzD_zg',\\\n",
    "#                 'mF2EW3twSrFPmT_RVV1-Qg', 'caq9CTtWB-8K0tdFUhTfAQ']\n",
    "business_ids = df['business_id'].sample(5).tolist()\n",
    "id_pair_counts = {}\n",
    "df2 = df[df[\"business_id\"].isin(business_ids)]\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "for i, row in df2.iterrows():\n",
    "    print(f\"{i}/{len(df2)}\")\n",
    "    business_id = row['business_id']\n",
    "    if business_id not in business_ids:\n",
    "        continue\n",
    "    if business_id not in id_pair_counts:\n",
    "        id_pair_counts[business_id] = {}\n",
    "    review = row['text']\n",
    "    sentences = nltk.tokenize.sent_tokenize(review)\n",
    "    noun_adj_pairs = []\n",
    "    for sentence in sentences:\n",
    "        noun_adj_pairs += get_noun_adjective_pairs_3(sentence)\n",
    "    row_pair_counts = dict(Counter(noun_adj_pairs))\n",
    "    print(row_pair_counts)\n",
    "    for pair, count in row_pair_counts.items():\n",
    "        if pair in id_pair_counts[business_id]:\n",
    "            id_pair_counts[business_id][pair] += count\n",
    "        else:\n",
    "            id_pair_counts[business_id][pair] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_top_5 = {}\n",
    "for business_id in id_pair_counts:\n",
    "    pair_counts = id_pair_counts[business_id]\n",
    "    top_5 = heapq.nlargest(5, pair_counts.items(), key=lambda item: item[1])\n",
    "    id_top_5[business_id] = top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"noun_adj.txt\", 'w') as f:\n",
    "    for business_id in id_top_5:\n",
    "        f.write(f\"business_id : {business_id}\" + '\\n')\n",
    "        for pair_count in id_top_5[business_id]:\n",
    "            f.write(f\"pair : {pair_count[0][0]}-{pair_count[0][1]} count: {pair_count[1]}\" + '\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
